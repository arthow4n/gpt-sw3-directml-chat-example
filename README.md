# gpt-sw3-directml-chat-example

Random notes for trying out Swedish large language model https://www.ai.se/sv/projekt/gpt-sw3 on my machine. I'm not a Python expert ü§∑‚Äç‚ôÇÔ∏è.

## Setup

```sh
# Download the models
cd ../
git lfs install
git clone https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b-instruct
git clone https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b

cd -
source venv/Scripts/activate
pip install -r requirements.txt # created using pipreqs
```

## Chat examples

```sh
# Enable the venv in the terminal first before running.
source venv/Scripts/activate
# Start the chat loop
python chat.py
```

### Grammar check

```
User: R√§tta spr√•kfelen i f√∂ljande meningen: Jag k√∂rt ett r√∂tt bil ig√•r.
Bot: Jag k√∂rde en r√∂d bil ig√•r.
```

```
User: R√§tta spr√•kfelen i f√∂ljande meningen: Jag ska k√∂r ett r√∂tt bil imorgon om jag beh√∂ver inte jobba.
Bot: Jag ska k√∂ra en r√∂d bil imorgon om jag inte beh√∂ver arbeta.
```

### Others

There're some hallucinations here.

```
User: Vad kostar en etta i G√∂teborg?
Bot: I genomsnitt kostar en l√§genhet i centrala G√∂teborg cirka 1,4 miljoner svenska kronor (2023) per m√•nad.

Det √§r v√§rt att notera att detta kan variera beroende p√• faktorer som plats, storlek och kvalitet p√• l√§genheten. Dessutom kan det finnas skillnader mellan olika 
delar av staden, s√• det √§r alltid en bra id√© att g√∂ra lite forskning innan du g√∂r en investering.
```

```
User: Vad kostar en etta i G√∂teborg?
Bot: Den genomsnittliga hyran f√∂r en l√§genhet i centrala G√∂teborg √§r runt 7 500 kronor per m√•nad. Detta kan dock variera beroende p√• en rad faktorer, inklusive plats, storlek och typ av egendom som anv√§nds.

Det √§r ocks√• v√§rt att notera att priset p√• en l√§genhet i centrala G√∂teborg kan variera kraftigt beroende p√• faktorer som l√§ge, storlek och typ av egendom som anv√§nds. Det √§r d√§rf√∂r viktigt att g√∂ra lite forskning och j√§mf√∂ra priser fr√•n olika k√§llor innan du g√∂r en bindande offert.
```

## Text generation example

```sh
# Enable the venv in the terminal first before running.
source venv/Scripts/activate
# Start the generation loop
python generation.py

# A file io/io.txt will be created upon start.
# 1. Edit io/io.txt and save, the content in that file will be used as prompt, this will trigger the text generation.
# 2. The process will generate and write back to io/io.txt.
# 3. Go back to 1., text generation is only triggered when the content of io/io.txt has changed.
```

# Known issues

The GPU loaded the language model and did the computation, but in the terminal it showed the warning message below:

```
C:\Users\...\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:823: UserWarning: The operator 'aten::repeat_interleave.Tensor' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at D:\a\_work\1\s\pytorch-directml-plugin\torch_directml\csrc\dml\dml_cpu_fallback.cpp:17.)
  input_ids = input_ids.repeat_interleave(expand_size, dim=0)
```
